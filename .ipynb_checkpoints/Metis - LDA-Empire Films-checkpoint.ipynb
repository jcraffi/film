{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\krist\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\krist\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\krist\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\krist\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk import stem\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Well, if Stanley Kubrick described it as \"poss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Star Wars: Episode V — The Empire Strikes Back</td>\n",
       "      <td>1980</td>\n",
       "      <td>The original “this one’s darker” sequel, and b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>Easily as influential on the genre as that oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>The warm, leathery embrace of Morgan Freeman’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1994</td>\n",
       "      <td>If Reservoir Dogs was a blood-spattered callin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                            Name  Year  \\\n",
       "0     1                                   The Godfather  1972   \n",
       "1     2  Star Wars: Episode V — The Empire Strikes Back  1980   \n",
       "2     3                                 The Dark Knight  2008   \n",
       "3     4                        The Shawshank Redemption  1994   \n",
       "4     5                                    Pulp Fiction  1994   \n",
       "\n",
       "                                         Description  \n",
       "0  Well, if Stanley Kubrick described it as \"poss...  \n",
       "1  The original “this one’s darker” sequel, and b...  \n",
       "2  Easily as influential on the genre as that oth...  \n",
       "3  The warm, leathery embrace of Morgan Freeman’s...  \n",
       "4  If Reservoir Dogs was a blood-spattered callin...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.empireonline.com/movies/features/best-movies/\n",
    "empire100 = pd.read_excel('C:/Users/krist/OneDrive/Documents/Python/film/empirefilms.xlsx')\n",
    "empire100.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopses = empire100['Description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source for Processing Raw Text: http://www.nltk.org/book/ch03.html\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "stemmer = stem.snowball.EnglishStemmer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "standard_words = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    final_list = []\n",
    "    for i in range(len(text)):\n",
    "        filtered_tokens = []\n",
    "        item=word_tokenize(text[i])\n",
    "        for word in item:\n",
    "             if re.search('^[a-zA-Z]+$', word):\n",
    "                filtered_tokens.append(word.lower())\n",
    "        final_list.append([stemmer.stem(word) for word in filtered_tokens if word not in stopwords and word in standard_words])\n",
    "    return final_list\n",
    "\n",
    "def tokenize_and_lem(text):\n",
    "    final_list = []\n",
    "    for i in range(len(text)):\n",
    "        filtered_tokens = []\n",
    "        item=word_tokenize(text[i])\n",
    "        for word in item:\n",
    "             if re.search('^[a-zA-Z]+$', word):\n",
    "                filtered_tokens.append(word.lower())\n",
    "        final_list.append([lemma.lemmatize(word) for word in filtered_tokens if word not in stopwords and word in standard_words])\n",
    "    return final_list\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "synopses_lemmed=tokenize_and_lem(synopses)\n",
    "synopses_lemma_string=[]\n",
    "for doc in synopses_lemmed:\n",
    "    synopses_lemma_string.append(\" \".join(str(x) for x in doc))\n",
    "\n",
    "print(type(synopses_lemma_string))\n",
    "print(len(synopses_lemma_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 0.010s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(synopses_lemma_string)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.006s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(synopses_lemma_string)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=2000 and n_features=100...\n",
      "done in 0.046s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: right feel film time like make truly good great course performance story little cinema new human man adventure hand ultimate\n",
      "Topic #1: big way action yes new great came make like white bad feature instead thanks movie inside half narrative kind release\n",
      "Topic #2: got drama better hard dark pretty original hand look director violence fantastic great perfectly course like people way world inside\n",
      "Topic #3: world war movie shoot epic got king old scene set make adventure best adaptation half henry sense western bad narrative\n",
      "Topic #4: movie turned best release horror good marvel pretty sense guy jack director despite form story performance better time adaptation love\n",
      "Topic #5: scene time work thriller thanks crime long twist tale remains white case way seven far guy best western action instead\n",
      "Topic #6: battle power cinema great future peter writer set action seven narrative fantastic day twist man case director got alien adventure\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=100...\n",
      "done in 0.050s.\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: movie good film right make story like time sense adventure bad adaptation old feel cinema man ultimate deeply perfectly day\n",
      "Topic #1: way big action new like great yes win human truly feel horror came course kind inside instead power director make\n",
      "Topic #2: drama got great fantastic little battle violence peter day cinema like le film writer man henry look inside set twist\n",
      "Topic #3: world movie release really set sense turned star feature narrative making war make half magic kelly king know western shoot\n",
      "Topic #4: movie director pretty better turned dark despite marvel performance novel best love feature jack guy came look perfectly form violence\n",
      "Topic #5: remains thriller thanks tale original crime work better truly different white scene modern epic long twist best course alien form\n",
      "Topic #6: time war future movie great power scene case seven narrative battle best kind shoot cinema horror writer thriller crime henry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=100...\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.160s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: like crime ultimate adventure really drama day power better best course perfectly love movie great action director world look marvel\n",
      "Topic #1: movie make great director release far film big case sense turned new white man despite story feature seven love writer\n",
      "Topic #2: film western man set little star like right peter making form epic world feature crime human came work thriller really\n",
      "Topic #3: movie time world war action epic good make cinema big shoot future like best novel course human adaptation old battle\n",
      "Topic #4: way hard twist cinema thriller half action better deeply horror director case alien movie performance turned remains big pretty drama\n",
      "Topic #5: film drama got right world story movie le central adaptation better war great truly best guy know original people violence\n",
      "Topic #6: thanks narrative win work alien truly scene tale world henry way day long feel power remains time modern crime turned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity values reported during training:\n",
      "Perplexity using normalized doc-topic matrix returned by lda.transform():\n",
      "405.66269449059587\n",
      "Perplexity using unnormalized doc-topic matrix returned by lda._e_step(), as used in lda.fit():\n",
      "405.66269449059587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krist\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:812: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if doc_topic_distr != 'deprecated':\n",
      "C:\\Users\\krist\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:816: DeprecationWarning: Argument 'doc_topic_distr' is deprecated and is being ignored as of 0.19. Support for this argument will be removed in 0.21.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity values reported during training:')\n",
    "lda.fit(tf)\n",
    "\n",
    "print('Perplexity using normalized doc-topic matrix returned by lda.transform():')\n",
    "print(lda.perplexity(tf))  # calls lda.transform(tf), which normalizes doc-topic-matrix\n",
    "\n",
    "print('Perplexity using unnormalized doc-topic matrix returned by lda._e_step(), as used in lda.fit():')\n",
    "print(lda.perplexity(tf, lda._e_step(tf,False,False)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
